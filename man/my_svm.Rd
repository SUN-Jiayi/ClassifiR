% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/my_svm.R
\name{my_svm}
\alias{my_svm}
\title{Linear SVM Classifier (from scratch) with Hyperparameter Tuning}
\usage{
my_svm(
  train_data,
  test_data,
  learning_rates = c(0.01),
  lambda_values = c(1e-04, 0.001, 0.01, 0.1),
  n_iter = 1000,
  tune = TRUE
)
}
\arguments{
\item{train_data}{A data frame. Last column is the binary label (0 or 1).}

\item{test_data}{A data frame. Last column is the binary label.}

\item{learning_rates}{A numeric vector of learning rates to try (e.g., c(0.001, 0.01)). Default is 0.01.}

\item{lambda_values}{A numeric vector of lambda (regularization) values to try. Default is c(0.0001, 0.001, 0.01, 0.1).}

\item{n_iter}{Number of training iterations. Default is 1000.}

\item{tune}{Logical. If TRUE, performs tuning. Default is TRUE.}
}
\value{
A list containing:
\item{weights}{The final trained weights.}
\item{predict_fun}{Prediction function.}
\item{prediction_train}{Predicted classes for training data.}
\item{probability_train}{Predicted probabilities for training data.}
\item{prediction}{Predicted classes for test data.}
\item{probability}{Predicted probabilities for test data.}
\item{best_lambda}{The selected lambda.}
\item{best_learning_rate}{The selected learning rate.}
}
\description{
Trains a linear SVM classifier using stochastic gradient descent with optional tuning
for both learning rate and regularization strength (lambda).
}
\examples{
# Create simple binary dataset
train_data <- data.frame(x1 = c(1, 2, 3, 4), x2 = c(1, 1, 0, 0), y = c(0, 0, 1, 1))
test_data <- data.frame(x1 = c(2, 3), x2 = c(1, 0), y = c(0, 1))

# Train SVM with tuning disabled
model <- my_svm(train_data, test_data, learning_rate = 0.01, n_iter = 10, tune = FALSE)
model$prediction
model$probability
}
\seealso{
\code{\link[assertthat]{assert_that}}
}

% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/boosting.R
\name{predict_adaboost_}
\alias{predict_adaboost_}
\title{Make Predictions Using an AdaBoost Model}
\usage{
predict_adaboost_(model, newdata)
}
\arguments{
\item{model}{A list representing the AdaBoost model, as returned by the \code{\link{adaboost_}} function.
It must contain the following elements:
\describe{
  \item{\code{models}}{A list of decision stumps, where each stump is a list with components:
    \code{feature} (column index), \code{threshold} (numeric split point), and \code{polarity} (either 1 or -1).}
  \item{\code{alphas}}{A numeric vector of weights (alpha values) corresponding to the accuracy of each weak learner.}
}}

\item{newdata}{A data frame of numeric features on which to make predictions. The feature columns must match those used during training (i.e., same order and number of columns as in the training data).}
}
\value{
An integer vector of predicted class labels (0 or 1), one for each row in \code{newdata}.
}
\description{
This function uses a trained AdaBoost model (produced by \code{\link{adaboost_}}) to make binary class predictions on new data.
The prediction is performed by aggregating the weighted votes of each decision stump (weak learner) in the model.
Each weak learner predicts either \code{-1} or \code{1}, and the final prediction is based on the sign of the weighted sum.
}
\details{
The prediction process works as follows:
\enumerate{
  \item Each weak learner (decision stump) makes a prediction of -1 or 1 on the new data based on its threshold and polarity.
  \item Each prediction is weighted by the corresponding alpha value (model confidence).
  \item The weighted predictions are summed for each row.
  \item The final predicted label is 1 if the sum is non-negative, and 0 otherwise.
}

This implementation assumes that the AdaBoost model was trained on data where the binary labels were originally \code{0} and \code{1}, and internally converted to \code{-1} and \code{1}.
The function converts the final result back to 0/1 format for user-friendly output.

If the model contains no weak learners (i.e., \code{model$models} is empty), a warning is issued and a vector of 0s is returned.
}
\examples{
\dontrun{
# Train an AdaBoost model
set.seed(123)
X <- data.frame(x1 = rnorm(100), x2 = rnorm(100))
y <- ifelse(X$x1 + X$x2 > 0, 1, 0)
model <- adaboost_(cbind(X, y), n_iter = 10)

# Predict on new data
new_X <- data.frame(x1 = rnorm(5), x2 = rnorm(5))
preds <- predict_adaboost_(model, new_X)
print(preds)
}

}
\seealso{
\code{\link{adaboost_}}, \code{\link{tune_adaboost_}}
}

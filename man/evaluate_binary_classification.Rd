% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/evaluation.R
\name{evaluate_binary_classification}
\alias{evaluate_binary_classification}
\title{Evaluate Binary Classification Model}
\usage{
evaluate_binary_classification(y_true, y_pred, y_prob = NULL)
}
\arguments{
\item{y_true}{True labels (vector of 0/1).}

\item{y_pred}{Predicted labels (vector of 0/1).1}

\item{y_prob}{Optional predicted probabilities (vector with values in [0, 1])}
}
\value{
A named list containing the following components:
\describe{
  \item{accuracy}{Proportion of correct predictions}
  \item{precision}{Proportion of predicted positives that are actually positive}
  \item{recall}{Proportion of actual positives that are correctly predicted}
  \item{specificity}{Proportion of actual negatives that are correctly predicted}
  \item{balanced_accuracy}{Average of recall and specificity}
  \item{f1}{Harmonic mean of precision and recall}
  \item{mcc}{Matthews Correlation Coefficient, a balanced metric even for imbalanced classes}
  \item{log_loss}{Logarithmic loss based on predicted probabilities (only if \code{y_prob} is provided)}
  \item{confusion_matrix}{A 2x2 matrix showing predicted vs actual values}
}
}
\description{
Computes key performance metrics for binary classification, including accuracy, precision, recall, F1 score, specificity, balanced accuracy,
Matthews correlation coefficient (MCC), log loss, and the confusion matrix. This function is useful for evaluating classifiers with predicted
labels and optional predicted probabilities.
}
\examples{
y_true = c(0, 1, 1, 0, 1, 0, 1, 0)
y_pred = c(0, 1, 1, 0, 0, 0, 1, 1)
y_prob = c(0.1, 0.9, 0.85, 0.2, 0.4, 0.3, 0.8, 0.7)
evaluate_binary_classification(y_true, y_pred, y_prob)

}

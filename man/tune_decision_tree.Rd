% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/decision_tree.R
\name{tune_decision_tree}
\alias{tune_decision_tree}
\title{Tune Decision Tree Hyperparameters}
\usage{
tune_decision_tree(
  X,
  y,
  max_depth_values = c(3, 5, 7, 9, 11),
  min_samples_split_values = c(20, 30, 50),
  criterion = "gini",
  split_ratio = 0.8,
  seed = 123
)
}
\arguments{
\item{X}{Feature data.frame.}

\item{y}{Target vector.}

\item{max_depth_values}{Vector of candidate max_depth values.}

\item{min_samples_split_values}{Vector of candidate min_samples_split values.}

\item{criterion}{Splitting criterion ("gini" or "entropy").}

\item{split_ratio}{Proportion of data used for training (default 0.8).}

\item{seed}{Random seed for reproducibility.}
}
\value{
A list with best parameters, best model, and best validation accuracy.
}
\description{
Performs a grid search over maximum depth and minimum split size to find the best decision tree configuration,
based on validation accuracy.
}
\examples{
# Create toy data
X = data.frame(
  x1 = c(2, 5, 4, 3, 7, 2),
  x2 = c(1, 2, 1, 1, 3, 2)
)
y = c(0, 0, 1, 1, 1, 0)

# Tune a decision tree model
tuning_result = tune_decision_tree(
  X, y,
  max_depth_values = c(2, 3),
  min_samples_split_values = c(2, 3),
  criterion = "gini",
  split_ratio = 0.8,
  seed = 123
)

# Print best parameters found
print(tuning_result$best_params)
print(paste("Best Validation Accuracy:", round(tuning_result$best_score, 4)))

}

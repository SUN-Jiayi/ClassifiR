% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/random_forest.R
\name{tune_random_forest}
\alias{tune_random_forest}
\title{Tune Random Forest Hyperparameters}
\usage{
tune_random_forest(
  X,
  y,
  mtry_values = NULL,
  nodesize_values = c(1, 5, 10),
  ntree = 100,
  split_ratio = 0.8,
  seed = 123
)
}
\arguments{
\item{X}{Feature data.frame.}

\item{y}{Target vector.}

\item{mtry_values}{A vector of candidate mtry values.}

\item{nodesize_values}{A vector of candidate nodesize values.}

\item{ntree}{Number of trees (fixed).}

\item{split_ratio}{Proportion for train/validation split.}

\item{seed}{Random seed.}
}
\value{
List with best model, best params, best validation accuracy.
}
\description{
Performs grid search over candidate \code{mtry} and \code{nodesize} values to select the best-performing random forest
model based on validation accuracy. The training set is split into train/validation according to \code{split_ratio}.
}
\examples{
# Create toy data
X = data.frame(
  x1 = c(1, 2, 3, 4, 5),
  x2 = c(5, 6, 7, 8, 9)
)
y = c(0, 0, 1, 1, 1)

# Tune a random forest model
result = tune_random_forest(
  X, y,
  mtry_values = c(1, 2),
  nodesize_values = c(1, 2),
  ntree = 50,
  split_ratio = 0.8,
  seed = 123
)

# Print best parameters found
print(result$best_params)
print(result$best_score)

}
